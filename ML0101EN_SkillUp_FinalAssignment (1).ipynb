{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n\n<h1 align=\"center\"><font size=\"5\">Final Project: Classification with Python</font></h1>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Table of Contents</h2>\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ul>\n    <li><a href=\"https://#Section_1\">Instructions</a></li>\n    <li><a href=\"https://#Section_2\">About the Data</a></li>\n    <li><a href=\"https://#Section_3\">Importing Data </a></li>\n    <li><a href=\"https://#Section_4\">Data Preprocessing</a> </li>\n    <li><a href=\"https://#Section_5\">One Hot Encoding </a></li>\n    <li><a href=\"https://#Section_6\">Train and Test Data Split </a></li>\n    <li><a href=\"https://#Section_7\">Train Logistic Regression, KNN, Decision Tree, SVM, and Linear Regression models and return their appropriate accuracy scores</a></li>\n</a></li>\n</div>\n<p>Estimated Time Needed: <strong>180 min</strong></p>\n</div>\n\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Instructions\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this notebook, you will  practice all the classification algorithms that we have learned in this course.\n\n\nBelow, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n\nWe will use some of the algorithms taught in the course, specifically:\n\n1. Linear Regression\n2. KNN\n3. Decision Trees\n4. Logistic Regression\n5. SVM\n\nWe will evaluate our models using:\n\n1.  Accuracy Score\n2.  Jaccard Index\n3.  F1-Score\n4.  LogLoss\n5.  Mean Absolute Error\n6.  Mean Squared Error\n7.  R2-Score\n\nFinally, you will use your models to generate the report at the end. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# About The Dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n\nThe dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n\n| Field         | Description                                           | Unit            | Type   |\n| ------------- | ----------------------------------------------------- | --------------- | ------ |\n| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n| Location      | Location of the Observation                           | Location        | object |\n| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n| RainToday     | If there was rain today                               | Yes/No          | object |\n| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n\nColumn definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## **Import the required libraries**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\nimport piplite\nawait piplite.install(['pandas'])\nawait piplite.install(['numpy'])\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport sklearn.metrics as metrics",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Importing the Dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await download(path, \"Weather_Data.csv\")\nfilename =\"Weather_Data.csv\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Weather_Data.csv\")\ndf.head()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Data Preprocessing\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### One Hot Encoding\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, we need to perform one hot encoding to convert categorical variables to binary variables.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Training Data and Test Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, we set our 'features' or x values and our Y or target variable.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.drop('Date',axis=1,inplace=True)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = df_sydney_processed.astype(float)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\nY = df_sydney_processed['RainTomorrow']",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Linear Regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot\n\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)\nprint('Train set:', x_train.shape, y_train.shape)\nprint('Test set:', x_test.shape, y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mx\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain set:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest set:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_test\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "LinearReg = linear_model.LinearRegression()\ntrain_x = np.asanyarray(train[['']])\ntrain_y = np.asanyarray(train[['']])\nLineraReg.fit(tain_x, train_y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'linear_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LinearReg \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m      2\u001b[0m train_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      3\u001b[0m train_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = LinearReg.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'LinearReg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mLinearReg\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LinearReg' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "LinearRegression_MAE = print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(predictions, y_test)))\nLinearRegression_MSE = print(\"Residual sum of sqaures(MSE): %.2f\" % np.mean((predictions, y_test)** 2))\nLinearRegression_R2 = print(\"R2 score : %.2f\" % r2_score(predictions, y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LinearRegression_MAE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean absolute error: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabsolute(predictions, y_test)))\n\u001b[1;32m      2\u001b[0m LinearRegression_MSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResidual sum of sqaures(MSE): \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((predictions, y_test)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      3\u001b[0m LinearRegression_R2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2 score : \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m r2_score(predictions, y_test))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Report = pd. Dataframe({'Metric':['Mean absolute error (MAE)' , 'Mean sqaured error (MSE)' , 'R-squared (R2)'] , 'value': [mae, mse, R2]})",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Report \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39m Dataframe({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean absolute error (MAE)\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean sqaured error (MSE)\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR-squared (R2)\u001b[39m\u001b[38;5;124m'\u001b[39m] , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: [mae, mse, R2]})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### KNN\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "KNN = KNeighborsClassifier(n_neignbors = 4).fit(x_ytrain , y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'KNeighborsClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m KNN \u001b[38;5;241m=\u001b[39m \u001b[43mKNeighborsClassifier\u001b[49m(n_neignbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(x_ytrain , y_train)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = KNN.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'KNN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mKNN\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KNN' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "KNN_Accuracy_Score = print (\"Accuracy:\" , metrics.accuracy_score(y_test , KNN.predict(x_test)))\nKNN_JaccardIndex = print (\"Jaccared index:\" , metrics.jaccard_score(y_test , KNN.predict(x_test)))\nKNN_F1_Score = print (\"F1 score:\" , metrics.F1_score(y_test , KNN.predict(x_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'metrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m KNN_Accuracy_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test , KNN\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      2\u001b[0m KNN_JaccardIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccared index:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mjaccard_score(y_test , KNN\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      3\u001b[0m KNN_F1_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 score:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mF1_score(y_test , KNN\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "# Decission Trees",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Tree = DecissionTreeClassifier().fit (x_train , y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'DecissionTreeClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Tree \u001b[38;5;241m=\u001b[39m \u001b[43mDecissionTreeClassifier\u001b[49m()\u001b[38;5;241m.\u001b[39mfit (x_train , y_train)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecissionTreeClassifier' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = Tree.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'Tree' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mTree\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tree' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Tree_Accuracy_Score = print (\"Accuracy:\" , metrics.accuracy_score(y_test , Tree.predict(x_test)))\nTree_JaccardIndex = print (\"Jaccared index:\" , metrics.jaccard_score(y_test , Tree.predict(x_test)))\nTree_F1_Score = print (\"F1 score:\" , metrics.F1_score(y_test , Tree.predict(x_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'metrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Tree_Accuracy_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test , Tree\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      2\u001b[0m Tree_JaccardIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccared index:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mjaccard_score(y_test , Tree\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      3\u001b[0m Tree_F1_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 score:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mF1_score(y_test , Tree\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic Regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split (x, y, test_size = 0.2, random_state = 1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split (\u001b[43mx\u001b[49m, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "LR = LogisticRegression(solver = 'liblinear').fit(x_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'LogisticRegression' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m(solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = LR.predict(x_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predict_proba = LR.predict_proba(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'LR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predict_proba \u001b[38;5;241m=\u001b[39m \u001b[43mLR\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(x_test)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LR' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code, Execute and take the Screenshot",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "LR_Accuracy_Score = print (\"Accuracy:\" , metrics.accuracy_score(y_test , LR.predict(x_test)))\nLR_JaccardIndex = print (\"Jaccared index:\" , metrics.jaccard_score(y_test , binary_LR.predict(x_test)))\nLR_F1_Score = print (\"F1 score:\" , metrics.F1_score(y_test , binary_LR.predict(x_test)))\nLR_Log_Loss = print (\"Log loss:\" , metrics.Log_loss(y_test , LR.predict_proba(x_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'metrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LR_Accuracy_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test , LR\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      2\u001b[0m LR_JaccardIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccared index:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mjaccard_score(y_test , binary_LR\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      3\u001b[0m LR_F1_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 score:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mF1_score(y_test , binary_LR\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "### SVM\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "SVM = svm().fit (x_train. y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'svm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SVM \u001b[38;5;241m=\u001b[39m \u001b[43msvm\u001b[49m()\u001b[38;5;241m.\u001b[39mfit (x_train\u001b[38;5;241m.\u001b[39m y_train)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = SVM.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'SVM' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mSVM\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVM' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "SVM_Accuracy_Score = print (\"Accuracy:\" , metrics.accuracy_score(y_test , svm.predict(x_test)))\nSVM_JaccardIndex = print (\"Jaccared index:\" , metrics.jaccard_score(y_test , svm.predict(x_test)))\nSVM_F1_Score = print (\"F1 score:\" , metrics.F1_score(y_test , svm.predict(x_test)))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'metrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SVM_Accuracy_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test , svm\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      2\u001b[0m SVM_JaccardIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccared index:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mjaccard_score(y_test , svm\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n\u001b[1;32m      3\u001b[0m SVM_F1_Score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 score:\u001b[39m\u001b[38;5;124m\"\u001b[39m , metrics\u001b[38;5;241m.\u001b[39mF1_score(y_test , svm\u001b[38;5;241m.\u001b[39mpredict(x_test)))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "### Report\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n\n\\*LogLoss is only for Logistic Regression Model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "Report = print (pd.DataFrame({\"Model\":[\"KNN\", \"Decission Trees\", \"Logistic Regression\", \"SVM\"],\"Accuracy\": [], \"Jaccard Index\": [],\"F1 score\": [], \"Log loss\": []}",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"Section_5\">  How to submit </h2>\n\n<p>Once you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n\n<p>This will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n\n### Other Contributors\n\n[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By    | Change Description          |\n| ----------------- | ------- | ------------- | --------------------------- |\n| 2022-06-22        | 2.0     | Svitlana K.   | Deleted GridSearch and Mock |\n\n## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}